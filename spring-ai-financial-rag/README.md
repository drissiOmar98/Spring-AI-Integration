# ğŸ“Š Spring AI â€” Financial RAG (Retrieval-Augmented Generation)

## Market Analysis â€¢ PDF Ingestion â€¢ AI-Powered Financial Insights

This project demonstrates how to build a **financial Retrieval-Augmented Generation (RAG)** system using **Spring AI** and **OpenAI**.

It ingests **financial market reports in PDF format**, stores their embeddings in a **vector database (pgvector)**, and enables **context-aware AI querying** over the extracted content.

The application allows you to ask questions about financial documents and receive **fact-grounded, accurate responses** generated by an AI model.

---

## ğŸ¯ Use Cases

This project is ideal for building:

- ğŸ“ˆ Financial research assistants
- ğŸ“„ Market report analysis tools
- ğŸ¦ Investment insight platforms
- ğŸ¤– AI-powered knowledge bases
- ğŸ“Š Economic trend exploration systems

---

## ğŸš€ Key Features

| Feature | Description |
|---------|-------------|
| ğŸ“¥ PDF Ingestion | Automatically loads and processes financial reports at startup |
| ğŸ§  Vector Embeddings | Converts document chunks into semantic embeddings |
| ğŸ—„ï¸ pgVector Storage | Stores embeddings in PostgreSQL using pgvector |
| ğŸ” Semantic Retrieval | Finds relevant document sections for each query |
| ğŸ¤– RAG-Enabled Chat | Uses `QuestionAnswerAdvisor` for grounded AI responses |
| âš¡ Auto Initialization | Loads vectors when the app starts |
| ğŸ”’ Secure API Config | Uses environment variables for OpenAI credentials |

## ğŸ“¦ Prerequisites

Before running the project, make sure you have:

- â˜• **Java 21+**
- ğŸ“¦ **Maven**
- ğŸ˜ **PostgreSQL with pgvector extension**
- ğŸ”‘ **OpenAI API Key**
- ğŸ³ **Docker & Docker Compose**

---



### ğŸ“ Directory & File Overview

| Path | Description |
|------|-------------|
| `IngestionService.java` | Loads and processes financial PDF documents at startup and stores embeddings in the vector database |
| `ChatController.java` | Exposes REST endpoints for querying the AI using Retrieval-Augmented Generation (RAG) |
| `src/main/resources/` | Holds configuration files and static resources |
| `docs/` | Directory for financial documents used as the knowledge base |
| `article_thebeatoutlook2026.pdf` | Market analysis report ingested and indexed for AI querying |
| `docker-compose.yml` | Defines PostgreSQL + pgvector services for vector storage |

---

### ğŸ§© Component Responsibilities

#### ğŸ“¥ `IngestionService`
- Runs automatically on application startup
- Reads financial PDF documents
- Splits content into semantic chunks
- Generates embeddings
- Stores vectors in pgvector

#### ğŸ¤– `ChatController`
- Handles user queries
- Integrates with Spring AI `ChatClient`
- Uses `QuestionAnswerAdvisor`
- Returns AI-generated, document-backed responses

#### ğŸ“„ `docs/`
- Serves as the document knowledge base
- New PDFs can be added here for re-indexing
- Supports future multi-document ingestion

#### ğŸ³ `docker-compose.yml`
- Starts PostgreSQL with pgvector support
- Enables persistent vector storage
- Simplifies local development setup


---

This structure ensures:

âœ… Clean separation of concerns  
âœ… Easy extensibility  
âœ… Scalable document ingestion  
âœ… Maintainable RAG architecture

New data sources, models, and endpoints can be added without disrupting the existing system.

## ğŸ”„ How It Works

This project follows a two-phase pipeline: **Document Ingestion** and **AI Querying**.

---

### ğŸ“Œ Startup: Document Ingestion

When the application starts, the system automatically prepares the knowledge base:

1. `IngestionService` is executed via `CommandLineRunner`.
2. Financial PDF files are loaded from `src/main/resources/docs`.
3. Documents are split into token-based semantic chunks.
4. Each chunk is converted into vector embeddings using OpenAI.
5. Embeddings are stored in PostgreSQL with pgvector support.
6. The vector store becomes available for semantic search.

This process runs once at startup and ensures the AI has access to structured financial knowledge.

---

### ğŸ“Œ Runtime: Query Processing

When a user sends a request:

1. The query is received by `ChatController`.
2. `QuestionAnswerAdvisor` performs semantic search on the vector store.
3. Relevant document chunks are retrieved.
4. Retrieved context is injected into the AI prompt.
5. OpenAI generates a grounded, context-aware response.
6. The final answer is returned to the client.

This retrieval step reduces hallucination and improves response accuracy by grounding answers in real financial data.

---

### âœ… Result

By combining ingestion and retrieval, the system delivers:

- Accurate financial insights
- Context-driven AI responses
- Reliable document-backed answers
- Scalable knowledge management

This architecture enables production-ready Retrieval-Augmented Generation (RAG) for financial applications.

